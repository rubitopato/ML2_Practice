{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb1da77",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "\n",
    "Federated learning is a machine learning paradigm that enables decentralized training of a shared model by multiple clients while preserving data privacy. The main idea behind this new paradigm is that each client trains a local model on its own data and then sends only the model updates to a central server, rather than sending the raw data. This allows the model to be trained on a large amount of data without compromising data privacy.\n",
    "\n",
    "Federated learning was first proposed by Google in 2016 (McMahan et al., 2016) and has since been applied in various fields, such as healthcare (Hard et al., 2018), finance (Yoon et al., 2018), and natural language processing (Li et al., 2020).  For example, federated learning could be used to train a model that can make personalized recommendations for each user without requiring the raw data from each user to be shared with a central server. This is the mechanism by which the model is trained on data, while adhering to data privacy requirements.\n",
    "\n",
    "Federated learning is a machine learning approach that offers numerous advantages over traditional centralized methods. Firstly, by leveraging distributed data stores, federated learning can scale to handle significantly larger datasets. Secondly, it prioritizes data privacy by avoiding the transmission of raw data to a central server. Finally, federated learning enables collaboration among multiple clients, allowing them to jointly train a shared model without compromising the security of their individual data. Overall, these benefits make federated learning a promising approach for machine learning in fields where data privacy is of the utmost importance.\n",
    "\n",
    "Federated learning is a process in which a central server distributes a machine learning model to multiple devices. Each device trains the model on its local data and sends the updated model back to the central server. The central server then aggregates the updates from each device to improve the global model. This process is repeated until the model converges and can generate accurate predictions on new data. The key concepts within this process are:\n",
    "\n",
    "\n",
    "* Client: refers to a device or edge node that holds a local dataset and actively participates in the training of the federated model.\n",
    "* Server: represents the central entity that coordinates the training of the federated model and receives model updates from the clients to aggregate into a new version of the global model.\n",
    "* Federated dataset: the collection of decentralized datasets from different clients that are used to train the federated model through collaborative learning.\n",
    "* Federated model: a machine learning model that is trained on the federated dataset using federated learning to make accurate predictions on new data while preserving the privacy of each client's data.\n",
    "* Federated optimization: refers to the process of training the federated model using the decentralized data and model updates from the clients, which enables the model to generalize better on unseen data while preserving the privacy of the clients.\n",
    "* Aggregation: the process of combining the model updates received from the clients into a new version of the global model. This can be done using various methods such as weighted averaging or other approaches.\n",
    "* Rounds: refer to the number of times a federated model is distributed among clients after performing an aggregation to train the model further. The process is repeated until the model converges and achieves a satisfactory level of accuracy.\n",
    "\n",
    "\n",
    "Federated learning is a relatively new approach, and as such, there are few libraries available that have adapted to it. The main actors in this space are TensorFlow Federated, PySyft, OpenMined, and Flower. Of these, TensorFlow Federated is a notable mention, although it is currently only a theoretical approach, as it does not allow for the deployment of the solution and only simulates the federated space. In contrast, Flower allows for the distribution of federated learning, although the necessary modifications can be somewhat challenging. For this tutorial, we have chosen Flower due to its more user-friendly approach and potential for future use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf254d5",
   "metadata": {},
   "source": [
    "# Introduction to Flower (FLWR)\n",
    "\n",
    "Flower is a Python library that offers tools for implementing the communication and coordination aspects of federated learning. Its design emphasizes ease of use and scalability. It's important to note that Flower is not a learning framework in itself, and as such, it wraps other machine learning frameworks like TensorFlow, PyTorch, or Scikit-learn in the communication layer to enable federated learning.\n",
    "\n",
    "To use Flower for federated learning, you will need to install the library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2f2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import flwr as fl\n",
    "except ImportError:\n",
    "    !pip install flwr[simulation] \n",
    "    import flwr as fl  # Import again after installation\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    !pip install tensorflow\n",
    "    import tensorflow as tf  # Import again after installation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82ce39",
   "metadata": {},
   "source": [
    "When setting up a simulation environment, it's crucial to use the `[simulation]` keyword with the `!pip install flwr[simulation]` command. This ensures that the necessary dependencies for simulating a federated learning environment, such as the `flwr_simulation` package, are also installed.\n",
    "\n",
    "**Important Note:** In a distributed setup, use `!pip install flwr` on both the server and all client devices to ensure consistency.\n",
    "\n",
    "**Installation Guide:**\n",
    "\n",
    "* For the most up-to-date and comprehensive installation instructions, refer to the official Flower documentation: [Link to official Flower documentation](https://flower.ai/)\n",
    "\n",
    "After installing the `flwr` package, import it into your Python code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b68fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a157b7b",
   "metadata": {},
   "source": [
    "FLWR provides a range of classes and functions that you can use to set up a federated learning environment, train and evaluate a model, and implement regular updates to the model. For more information, refer to the FLWR [documentation](https://flower.dev/docs/quickstart-tensorflow.html). Before proceeding, it's important to note that the model you define must be serializable so that it can be sent through the network. Not all models are suitable for federated learning. For this example, we'll be using an Artificial Neural Network (ANN) based on TensorFlow, specifically Keras. These models are generally lightweight and well-suited for serialization compared to some other model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd89deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model using TensorFlow\n",
    "def generate_ann():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(32, 32, 3)), #input data. 32x32 color images with 3 channels\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"), #hidden layer\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),#hidden layer\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"), #output layer. 10 classes\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167daad",
   "metadata": {},
   "source": [
    "As we will be using a Deep Learning model defined in TensorFlow, it's recommended to load the data into a `Dataset` class to enable the framework to leverage any available hardware acceleration (such as a GPU on the nodes). However, due to some limitations of the framework to serialize the data, it has to be done manually with the following lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b84ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/utils/file_utils.py:115: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  archive.extractall(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "NUM_CLIENTS = 5\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def split_index(a, n):\n",
    "    s = np.array_split(np.arange(len(a)), n)\n",
    "    return s\n",
    "\n",
    "\n",
    "# Code to load the dataset\n",
    "def load_datasets(num_clients: int):\n",
    "    # Distribute it to train and test set\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalize data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    x_train, y_train = x_train[:10_000], y_train[:10_000]\n",
    "    x_test, y_test = x_test[:1000], y_test[:1000]\n",
    "\n",
    "    # Randomize the datasets\n",
    "    x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "    x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "    # Split training set into NUM_CLIENTS partitions to simulate the individual dataset\n",
    "    train_index = split_index(x_train, num_clients)\n",
    "    test_index = split_index(x_test, num_clients)\n",
    "\n",
    "    # Split each partition\n",
    "    train_ds = []\n",
    "    val_ds = []\n",
    "    test_ds = []\n",
    "    for cid in range(num_clients):\n",
    "        val_size = len(train_index[cid]) // 10\n",
    "        train_input_data, train_output_data = x_train[train_index[cid]], y_train[train_index[cid]]\n",
    "        val_input_data, val_output_data = train_input_data[:val_size], train_output_data[:val_size]\n",
    "        train_input_data, train_output_data = train_input_data[val_size:], train_output_data[val_size:]\n",
    "        train_dataset = (train_input_data, train_output_data)\n",
    "        val_dataset = (val_input_data, val_output_data)\n",
    "        test_dataset = (x_test[test_index[cid]], y_test[test_index[cid]])\n",
    "        train_ds.append(train_dataset)\n",
    "        val_ds.append(val_dataset)\n",
    "        test_ds.append(test_dataset)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754d7f5",
   "metadata": {},
   "source": [
    "Before proceeding, it's crucial to perform a basic test to validate the correctness of our approach. This involves training the model on the dataset of a single client. The purposes are:\n",
    "1. **Checks Model Training Functionality**: It ensures that the model can be successfully trained on the data of an individual client.\n",
    "Identifies\n",
    "2. **Potential Issues Early**: It helps to detect and address any errors or unexpected behavior in the data loading or model training processes before moving on to the more complex federated learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fe1172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1250 - loss: 2.4288\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.1058 - loss: 2.4598\n",
      "The resulting loss is 2.409999132156372 for an accuracy in test of 1.1000%\n"
     ]
    }
   ],
   "source": [
    "model = generate_ann()\n",
    "\n",
    "model.fit(trainloaders[0][0],trainloaders[0][1], epochs=1, batch_size=32, steps_per_epoch=3)\n",
    "loss, accuracy = model.evaluate(valloaders[0][0], valloaders[0][1])\n",
    "print(f\"The resulting loss is {loss} for an accuracy in test of {accuracy*10:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78c70c",
   "metadata": {},
   "source": [
    "**Important**: *The following example is thought to be executed in a terminal* \n",
    "\n",
    "Starting from that point, that it works on a particular data, the federated processs is going to split this process in several machines and for that it is going to require de definition of a couple of additional elements. Therefore, let's introduce the two pieces of the puzzle: the `Client` and the `Server`. \n",
    "\n",
    "\n",
    "\n",
    "Flower starts a `Server` to coordinate the client devices and perform the orchestration of the model. The server interacts with clients through an interface called `Client`. When the server selects a particular client for training, it sends training instructions over the network. The client receives those instructions and calls one of the Client methods to run your code, which in this case involves training the neural network that we defined earlier.\n",
    "\n",
    "Flower provides a convenient class called NumPyClient, which simplifies the implementation of the Client interface when your workload uses Keras. The [NumPyClient](https://flower.ai/docs/framework/ref-api/flwr.client.NumPyClient.html#flwr.client.NumPyClient) interface defines three methods that can be implemented in the following way:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bde54e",
   "metadata": {},
   "source": [
    "```python\n",
    "#Create a class to contain the details of the client and be the interface\n",
    "class MyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, train_dataset, test_dataset):\n",
    "        self.model = net\n",
    "        self.trainloader = train_dataset\n",
    "        self.valloader = test_dataset\n",
    "        \n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.trainloader[0],self.trainloader[1], epochs=1, batch_size=32, steps_per_epoch=3)\n",
    "        return self.model.get_weights(), len(self.trainloader[0]), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, accuracy = self.model.evaluate(self.valloader[0], self.valloader[1])\n",
    "        return loss, len(self.valloader[0]), {\"accuracy\": float(accuracy)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324ea6a",
   "metadata": {},
   "source": [
    "In the preceding code, we defined the required functions for the client in this particular case. With these functions in place, we can now start a client using the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e187591",
   "metadata": {},
   "source": [
    "```python \n",
    "# Start the client\n",
    "model=generate_ann()\n",
    "\n",
    "fl.client.start_client(server_address=f\"localhost:8080\", client=MyClient(model,trainloaders[0],valloaders[0]).to_client())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d96b24",
   "metadata": {},
   "source": [
    "**Important**: In order to run the client you must need also a server running!!! You will executed both in separated terminals\n",
    "\n",
    "The string`localhost:8080` specifies the server to which the client should connect. In this case, as the code is being run on the same machine as the server, this address is sufficient. In a truly federated workload, the only thing that needs to be changed is the `server_address` to point the client to the correct server.\n",
    "\n",
    "Note that Jupyter usually runs on port 8080, **so you will need to use another available port if Jupyter server is running**.\n",
    "\n",
    "\n",
    "The other essential piece of the puzzle is the class that will contain the server. This will be in a separate file, for example, server.py, and its contents should look something like this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb282a",
   "metadata": {},
   "source": [
    "```python\n",
    "import flwr as fl\n",
    "\n",
    "fl.server.start_server(config=fl.server.ServerConfig(num_rounds=3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684abf1",
   "metadata": {},
   "source": [
    "##### **Important**\n",
    "You can use another port for running the server if you fix the following parameter in the `start_server` function: `server_address=\"localhost:8080\"`\n",
    "\n",
    "In this particular case, we can run two clients and a server in separate terminals of the machine. Running two client instances is as simple as executing the `python client.py` command twice in separate terminals, while the server can be started with the `python server.py` command.\n",
    "\n",
    "Upon starting the server, we should receive an output similar to:\n",
    "\n",
    "\n",
    "```shell\n",
    "INFO flwr 2023-03-01 14:58:16,353 | app.py:139 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
    "INFO flwr 2023-03-01 14:58:16,362 | app.py:152 | Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
    "INFO flwr 2023-03-01 14:58:16,362 | server.py:86 | Initializing global parameters\n",
    "INFO flwr 2023-03-01 14:58:16,362 | server.py:270 | Requesting initial parameters from one random client\n",
    "INFO flwr 2023-03-01 14:58:24,152 | server.py:274 | Received initial parameters from one random client\n",
    "INFO flwr 2023-03-01 14:58:24,153 | server.py:88 | Evaluating initial parameters\n",
    "INFO flwr 2023-03-01 14:58:24,153 | server.py:101 | FL starting\n",
    "DEBUG flwr 2023-03-01 14:58:26,118 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:27,041 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
    "WARNING flwr 2023-03-01 14:58:27,076 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
    "DEBUG flwr 2023-03-01 14:58:27,076 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:27,565 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
    "WARNING flwr 2023-03-01 14:58:27,565 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
    "DEBUG flwr 2023-03-01 14:58:27,566 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:28,015 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
    "DEBUG flwr 2023-03-01 14:58:28,027 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:28,364 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
    "DEBUG flwr 2023-03-01 14:58:28,364 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:28,755 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
    "DEBUG flwr 2023-03-01 14:58:28,769 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flwr 2023-03-01 14:58:29,184 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
    "INFO flwr 2023-03-01 14:58:29,185 | server.py:144 | FL finished in 5.031599427999936\n",
    "INFO flwr 2023-03-01 14:58:29,185 | app.py:202 | app_fit: losses_distributed [(1, 2.3956351280212402), (2, 2.426431179046631), (3, 2.3015435934066772)]\n",
    "INFO flwr 2023-03-01 14:58:29,185 | app.py:203 | app_fit: metrics_distributed {}\n",
    "INFO flwr 2023-03-01 14:58:29,186 | app.py:204 | app_fit: losses_centralized []\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8f5a6",
   "metadata": {},
   "source": [
    "With that, the first federated learning approach is completed. As you can see, the system goes through three rounds of fitting and evaluating on all clients before the results are retrieved, aggregated, and redistributed to the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa2154-a71c-4ed2-b932-29e26addf00d",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Implement the client and server code in separate files (**All the required files must be submitted together with the Notebook**). Next, execute a server and two clients from terminals. Finally, compare the results with those presented here. Were your results similar?\n",
    "\n",
    "\n",
    "**Note**:  The answer is expected to contain the corresponding terminal output resulting from the execution of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2140ca-a897-4d2e-817a-2b061a927a85",
   "metadata": {},
   "source": [
    "`Answer here`: \n",
    "\n",
    "Files can be found in the `U04 Simlation` folder.\n",
    "\n",
    "Server terminal output:\n",
    "\n",
    "```shell\n",
    "(ml2) albertolandi@Albertos-MacBook-Air U04 Simulation % python server.py\n",
    "WARNING :   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
    "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
    "\n",
    "\t\t$ flower-superlink --insecure\n",
    "\n",
    "\tTo view usage and all available options, run:\n",
    "\n",
    "\t\t$ flower-superlink --help\n",
    "\n",
    "\tUsing `start_server()` is deprecated.\n",
    "\n",
    "            This is a deprecated feature. It will be removed\n",
    "            entirely in future versions of Flower.\n",
    "        \n",
    "INFO :      Starting Flower server, config: num_rounds=3, no round_timeout\n",
    "INFO :      Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
    "INFO :      [INIT]\n",
    "INFO :      Requesting initial parameters from one random client\n",
    "INFO :      Received initial parameters from one random client\n",
    "INFO :      Starting evaluation of initial global parameters\n",
    "INFO :      Evaluation returned no results (`None`)\n",
    "INFO :      \n",
    "INFO :      [ROUND 1]\n",
    "INFO :      configure_fit: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_fit: received 2 results and 0 failures\n",
    "WARNING :   No fit_metrics_aggregation_fn provided\n",
    "INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_evaluate: received 2 results and 0 failures\n",
    "WARNING :   No evaluate_metrics_aggregation_fn provided\n",
    "INFO :      \n",
    "INFO :      [ROUND 2]\n",
    "INFO :      configure_fit: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_fit: received 2 results and 0 failures\n",
    "INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_evaluate: received 2 results and 0 failures\n",
    "INFO :      \n",
    "INFO :      [ROUND 3]\n",
    "INFO :      configure_fit: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_fit: received 2 results and 0 failures\n",
    "INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
    "INFO :      aggregate_evaluate: received 2 results and 0 failures\n",
    "INFO :      \n",
    "INFO :      [SUMMARY]\n",
    "INFO :      Run finished 3 round(s) in 135.70s\n",
    "INFO :      \tHistory (loss, distributed):\n",
    "INFO :      \t\tround 1: 2.3193126916885376\n",
    "INFO :      \t\tround 2: 2.3956093788146973\n",
    "INFO :      \t\tround 3: 2.30367910861969\n",
    "INFO :      \n",
    "(ml2) albertolandi@Albertos-MacBook-Air U04 Simulation % \n",
    "```\n",
    "\n",
    "- When comparing both:\n",
    "\n",
    "The results obtained were similar to those presented in the notebook, although the exact loss values differed slightly.  This is expected due to the inherent randomness in model initialization and data partitioning in federated learning.\n",
    "\n",
    "A comparison of the distributed losses is presented below:\n",
    "\n",
    "| Round | Obtained Loss   | Example's Loss      |\n",
    "|-------|-----------------|---------------------|\n",
    "| 1     | 2.3193          | 2.3956              |\n",
    "| 2     | 2.3956          | 2.4264              |\n",
    "| 3     | 2.3036          | 2.3015              |\n",
    "\n",
    "While the numerical values are not identical, the general trend is consistent: the loss fluctuates and generally decreases across rounds, which indicates that the federated model is learning.  The slight variations are likely attributable to differences in the random shuffling of the data and the initial weights of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf25335",
   "metadata": {},
   "source": [
    "# Updating parameters\n",
    "The key element in this kind of approach is that the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data, which changes the model parameters locally. After training, the updated model parameters are sent back to the server, or alternatively, only the gradients are sent back to the server, not the full model parameters.\n",
    "\n",
    "\n",
    "In `flwr`, this communication is essentially done by two helper functions for loading and retrieving local parameters: `set_parameters` and `get_parameters`. This requirement fits well with non-state approaches such as **PyTorch** or **JAX**. As demonstrated in the previous example, `flwr` can also be used with **TensorFlow** or even **scikit-learn**.\n",
    "\n",
    "As a result, the basic structure for any client using this library has the same format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467be0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Utility functions for the most common operations\n",
    "def get_parameters(net) -> List[np.array]:\n",
    "    return net.get_weights()\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    net.set_weights(parameters)\n",
    "    return net\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    net.fit(trainloader[0], trainloader[1],\n",
    "            epochs=epochs, batch_size=32, steps_per_epoch=3)\n",
    "    return net\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    loss, accuracy = net.evaluate(testloader[0], testloader[1])\n",
    "    return loss, accuracy\n",
    "\n",
    "# Class to contain a Client\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        self.net = train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"[Client {self.cid}] loss:{loss}, Client {self.cid} accuracy:{accuracy}\")\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508e352",
   "metadata": {},
   "source": [
    "In Flower, clients can be created by extending either the `flwr.client.Client` or `flwr.client.NumPyClient` classes. In the previous example, we used `NumPyClient` because it is easier to implement and requires less code as a template. Along with the extended class, there are three main methods that need to be implemented:\n",
    "\n",
    "* `get_parameters`: Returns the current local model parameters.\n",
    "* `fit`: Receives model parameters from the server, trains the model parameters on the local data, and returns the (updated) model parameters to the server.\n",
    "* `evaluate`: Receives model parameters from the server, evaluates the model parameters on the local data, and returns the evaluation result to the server.\n",
    "\n",
    "As you can see, the `MyClient` class implemented in the previous example follows this same structure and the diference is the *id* of the client which is stored for later convinience use in accesing the data.\n",
    "\n",
    "\n",
    "#### Be aware: \n",
    "Sometimes, especially when we are simulating multiple clients on a single device, it can be useful to use a function to create the client when it is required. This is particularly important in stateless frameworks, such as PyTorch, which can benefit from a more efficient implementation that creates clients only when they are required for training or evaluation. For example, the following code loads different examples for each client before discarding them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f967498e-6ab5-4f86-8b01-ba14d3053528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "from flwr.client import ClientApp\n",
    "\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    \"\"\"Returns a FlowerClient containing its data partition.\"\"\"\n",
    "    \n",
    "    # Create the model\n",
    "    net = generate_ann()\n",
    "    #get the identification\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    #Take the appropiate part of the dataset\n",
    "    trainloader = trainloaders[int(partition_id)]\n",
    "    valloader = valloaders[int(partition_id)]\n",
    "    #Create and return the Client\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa0980-ca68-4d44-a045-d7a4e1480e9d",
   "metadata": {},
   "source": [
    "From versión 1.13 onward, in order to run the simulation it is manadatory that the clients are contained inse a `ClientApp`. This represent each one of the nodes that are going to be used and call later by the simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58a8089-7553-40a8-882b-2eb846300f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concstruct the ClientApp passing the client generation function\n",
    "client_app = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eeb598",
   "metadata": {},
   "source": [
    "Note that `myClient` cannot be used in the same sense because of the state that it keeps internally through the function `generate_ann`. However, if this state is removed, it can be used in the same waysimilarly the this CLientFlower.\n",
    "\n",
    "The clients are now set up to load, fit, and evaluate. However, we need to integrate the results from the different clients. In Flower terminology, this is known as a strategy, such as the *Federated Average (FedAvg)* strategy. In a first approach, we can use the built-in implementations of the framework, although custom strategies can also be used. Additionally all those elements has to be set in an object in the Flower ecosystem with a `ServerApp` in order to run them.It has a similar signature to `client_fn` but, instead of returning a client object, it returns all the components needed to run the server-side logic in Flower. Let's see an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c5ea32-905b-4530-911a-648dde98b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.server import ServerApp, ServerAppComponents\n",
    "\n",
    "num_rounds = 3\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    # instantiate the model\n",
    "    model = generate_ann()\n",
    "    params = get_parameters(model)# The federated model initial parameters\n",
    "    del model # this is not require but it saves a good amount of memory\n",
    "    # Convert model parameters to flwr.common.Parameters\n",
    "    global_model_init = fl.common.ndarrays_to_parameters(params)\n",
    "\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "            fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "            min_fit_clients=NUM_CLIENTS,  # Never sample less than NUM_CLIENTS clients for training\n",
    "            min_evaluate_clients=NUM_CLIENTS//2,  # Never sample less than NUM_CLIENTS//2 clients for evaluation\n",
    "            min_available_clients=NUM_CLIENTS,  # Wait until all NUM_CLIENTS clients are available\n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(params), # Initial parameters\n",
    "    )\n",
    "\n",
    "    # Define ServerConfig\n",
    "    config=fl.server.ServerConfig(num_rounds=5)\n",
    "\n",
    "    # Return the configuration and strategy for this server\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create Server\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd740d-9393-4b64-bbff-cabbdcc15300",
   "metadata": {},
   "source": [
    "Now we have the two pieces of the puzzle. Therefore, the simulation engine can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e386a3-1167-4fb9-8678-81444bd61966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m /Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m   super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0846 - loss: 2.7059  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m [Client 2] loss:2.4528427124023438, Client 2 accuracy:0.13500000536441803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.1097 - loss: 2.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0800 - loss: 2.2840  \u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60499)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.0938 - loss: 2.2489\n",
      "\u001b[36m(ClientAppActor pid=60499)\u001b[0m [Client 4] loss:2.283036708831787, Client 4 accuracy:0.08500000089406967\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1185 - loss: 2.2964  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x17f8bfb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[36m(ClientAppActor pid=60502)\u001b[0m /Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60502)\u001b[0m   super().__init__(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60502)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x39605f600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.1791 - loss: 2.2584\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1576 - loss: 2.2680  \u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m [Client 1] loss:2.244774103164673, Client 1 accuracy:0.17000000178813934\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x1770b09a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 28.14s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.425778865814209\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.283255696296692\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 2.2986581325531006\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.2372995615005493\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.250061869621277\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.1451 - loss: 2.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m \u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[36m(ClientAppActor pid=60500)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x17726bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60502)\u001b[0m \u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.2247 - loss: 2.2556\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60501)\u001b[0m [Client 4] loss:2.264850378036499, Client 4 accuracy:0.20000000298023224\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8e116",
   "metadata": {},
   "source": [
    "This code corresponds to the script running on the server, and it uses the simulation function to test this approach on a single device with the previously mentioned optimization to avoid overloading the device. The code generates NUM_CLIENTS clients and randomly selects all of them (`fraction_fit = 1.0`) to train the model on all of them. After receiving the updates from the clients, the server performs the aggregation strategy before returning the global model to the clients for the next 3 rounds.\n",
    "\n",
    "**Note**: *Be aware that the simulation is a really resource consuming task. You can get some errors and warnings linked to that. There are different [configurations](https://flower.ai/docs/framework/how-to-run-simulations.html) that you can apply to configure the available resources for simulating the process.*\n",
    "\n",
    "One point to highlight is that the framework is not only going to manage the `losses_distributed`, but none of the other metrics. Due to the diverse treatment of those measures, the framework cannot accurately handle the aggregation of these metrics. Users need to tell the framework how to handle and aggregate these custom metrics.\n",
    "\n",
    "The strategy will then call these functions whenever it receives fit or evaluates metrics from clients. The two possible functions are `fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`. For example, the following code creates the weighted average, and the previous example can be adapted as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[36m(ClientAppActor pid=60676)\u001b[0m /Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[36m(ClientAppActor pid=60676)\u001b[0m   super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1029 - loss: 2.5617  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 1] loss:2.3321657180786133, Client 1 accuracy:0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.0920 - loss: 2.3105\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.0938 - loss: 2.3204\n",
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60676)\u001b[0m [Client 3] loss:2.3395631313323975, Client 3 accuracy:0.08500000089406967\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1224 - loss: 2.3107  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x39036e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[36m(ClientAppActor pid=60678)\u001b[0m /Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60678)\u001b[0m   super().__init__(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.2500 - loss: 2.3052\n",
      "\u001b[36m(ClientAppActor pid=60678)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1771 - loss: 2.2963  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x17a721580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.1523 - loss: 2.2593\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m [Client 3] loss:2.267077684402466, Client 3 accuracy:0.16500000655651093\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60678)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x178224860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 24.41s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.3492780923843384\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.34087336063385\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 2.3386341333389282\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.2789441347122192\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.3168126344680786\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.12000000104308128),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.07249999977648258),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.13249999657273293),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.14000000432133675),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.08999999985098839)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.0856 - loss: 2.2920\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m [Client 3] loss:2.316067695617676, Client 3 accuracy:0.08500000089406967\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=60677)\u001b[0m [Client 4] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=60679)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x3861a7c40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "from flwr.common import Metrics\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    # instantiate the model\n",
    "    model = generate_ann()\n",
    "    params = get_parameters(model)# The federated model initial parameters\n",
    "    del model # this is not require but it saves a good amount of memory\n",
    "    # Convert model parameters to flwr.common.Parameters\n",
    "    global_model_init = fl.common.ndarrays_to_parameters(params)\n",
    "\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "            fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "            min_fit_clients=NUM_CLIENTS,  # Never sample less than NUM_CLIENTS clients for training\n",
    "            min_evaluate_clients=NUM_CLIENTS//2,  # Never sample less than NUM_CLIENTS//2 clients for evaluation\n",
    "            min_available_clients=NUM_CLIENTS,  # Wait until all NUM_CLIENTS clients are available\n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(params), # Initial parameters\n",
    "            evaluate_metrics_aggregation_fn=weighted_average,  # put the metric aggregation for the evaluation\n",
    "    )\n",
    "\n",
    "    # Define ServerConfig\n",
    "    config=fl.server.ServerConfig(num_rounds=5)\n",
    "\n",
    "    # Return the configuration and strategy for this server\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "    \n",
    "# Create Server\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7ba45",
   "metadata": {},
   "source": [
    "We will revisit the definition of custom strategies in the following unit to define our own strategy and attempt to minimize some of the challenges that federated learning must address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52ac8c",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now is your turn, why not you try to run your own architecture with this approach. Beaware of the high requirements when we are in a simulated environment.\n",
    "\n",
    "**Note**: The objective of this exercise is to bring together the various topics covered by this notebook. This cell should contain all the necessary code for autonomous execution using Flower simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4ce7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertolandi/anaconda3/envs/ml2/lib/python3.12/site-packages/keras/src/utils/file_utils.py:115: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  archive.extractall(\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 1/5\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.1875 - loss: 3.4580\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.0469 - loss: 4.2635\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.1393 - loss: 3.5347\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.1641 - loss: 3.0873\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.1250 - loss: 3.1855 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.1146 - loss: 3.3096\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m Epoch 1/5\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2188 - loss: 3.5549\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1007 - loss: 3.5723\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0930 - loss: 2.3369\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 3] loss:2.3192365169525146, Client 3 accuracy:0.10000000149011612\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1784 - loss: 3.3691\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0964 - loss: 3.6094\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.0547 - loss: 4.4072\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1862 - loss: 3.2014\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0859 - loss: 3.6967\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 2/5\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.1328 - loss: 3.1040\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.1562 - loss: 2.9764\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1406 - loss: 3.0021\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1182 - loss: 2.3087\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 2] loss:2.3234922885894775, Client 2 accuracy:0.10499999672174454\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2135 - loss: 3.1656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.2135 - loss: 2.9585\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.2500 - loss: 2.8419\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1172 - loss: 3.1468\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.1875 - loss: 3.1888\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1133 - loss: 3.3060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0659 - loss: 2.3471    \n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 0] loss:2.3359527587890625, Client 0 accuracy:0.07500000298023224\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m Epoch 5/5\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0963 - loss: 2.3721\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.0625 - loss: 2.4558\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.1562 - loss: 2.9919\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.1875 - loss: 2.9453\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1497 - loss: 3.1886\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.1901 - loss: 3.0379\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1484 - loss: 2.8615\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2734 - loss: 2.5204\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1536 - loss: 2.8507\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 3] loss:2.344329595565796, Client 3 accuracy:0.09000000357627869\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m Epoch 5/5\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1693 - loss: 3.1193\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3125 - loss: 2.5586\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1162 - loss: 2.3146\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] loss:2.3245849609375, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2500 - loss: 2.6459\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0995 - loss: 2.3445\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3099 - loss: 2.6232\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.1862 - loss: 2.8869\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.1953 - loss: 2.8282\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m Epoch 1/5\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.1562 - loss: 3.3957\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1172 - loss: 3.2002\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.1562 - loss: 2.9667\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 1] loss:2.343479871749878, Client 1 accuracy:0.09000000357627869\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1953 - loss: 3.2423\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1016 - loss: 3.0185\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1367 - loss: 3.1343\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.1315 - loss: 3.1994\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1172 - loss: 3.1930\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.1979 - loss: 3.0783\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2357 - loss: 2.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 5/5\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 3] loss:2.430224657058716, Client 3 accuracy:0.09000000357627869\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1162 - loss: 2.3538 \n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.0625 - loss: 2.6197\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0963 - loss: 2.4730\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.1719 - loss: 2.8205\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.1719 - loss: 2.9526\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2018 - loss: 2.9690\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - accuracy: 0.2695 - loss: 2.7768\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1562 - loss: 2.9328\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.1966 - loss: 2.5880\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3359 - loss: 2.3787 \n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 5/5\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] loss:2.364698886871338, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2266 - loss: 2.8035 \n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.0938 - loss: 2.9490\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.1328 - loss: 2.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2227 - loss: 2.8600\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2435 - loss: 2.5237\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2344 - loss: 2.8860\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2721 - loss: 2.3830\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1693 - loss: 2.8852\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1406 - loss: 2.8524\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1271 - loss: 2.4202\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 2] loss:2.475313186645508, Client 2 accuracy:0.11500000208616257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0963 - loss: 2.5263\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 5/5\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.1914 - loss: 2.8745\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1562 - loss: 2.9961\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3125 - loss: 2.4350\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2422 - loss: 2.6710\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.1654 - loss: 2.8954\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.2669 - loss: 2.5702\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.2109 - loss: 2.5439\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.2786 - loss: 2.7354\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 3] loss:2.478419542312622, Client 3 accuracy:0.09000000357627869\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.1602 - loss: 3.0024\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m Epoch 4/5\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1172 - loss: 3.1034\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.2031 - loss: 2.7325\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2096 - loss: 2.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1562 - loss: 2.7812\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step - accuracy: 0.2448 - loss: 2.7988\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1719 - loss: 2.8483 \u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1849 - loss: 2.8942\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1162 - loss: 2.4318\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] loss:2.4429073333740234, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0590 - loss: 2.5800    \n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 1/5\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1875 - loss: 2.7206\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.2656 - loss: 2.7856\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.1549 - loss: 2.6018\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1641 - loss: 2.5514\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2500 - loss: 2.6278\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2513 - loss: 2.6652\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1797 - loss: 2.7422\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1745 - loss: 2.7580\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.3359 - loss: 2.5165\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.2422 - loss: 2.7902\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 0] loss:2.5492637157440186, Client 0 accuracy:0.07000000029802322\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2240 - loss: 2.7356\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step - accuracy: 0.3451 - loss: 2.3348\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m Epoch 5/5\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3424 - loss: 2.5004\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3594 - loss: 2.4571\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2734 - loss: 2.7578\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1562 - loss: 2.7133\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0518 - loss: 2.6611     \n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 0] loss:2.6038098335266113, Client 0 accuracy:0.07000000029802322\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1162 - loss: 2.4739\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.1562 - loss: 2.8280\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.1562 - loss: 2.8042\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2227 - loss: 2.6338\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m Epoch 1/5\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1719 - loss: 2.5173\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.2734 - loss: 2.4310\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0590 - loss: 2.6396\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.2240 - loss: 2.4194\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2812 - loss: 2.6236\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.2656 - loss: 2.7224\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2344 - loss: 2.7536\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 4] loss:2.4867143630981445, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2344 - loss: 2.8458\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2500 - loss: 2.9512\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2422 - loss: 2.6176\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.3346 - loss: 2.2550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2161 - loss: 2.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m Epoch 5/5\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2188 - loss: 2.9102\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2435 - loss: 2.7771\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1250 - loss: 2.8568\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3359 - loss: 2.4060\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1271 - loss: 2.5511\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 2] loss:2.625462293624878, Client 2 accuracy:0.11500000208616257\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3346 - loss: 2.1978\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.3672 - loss: 2.1239\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2057 - loss: 2.7377\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2370 - loss: 2.6323\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2005 - loss: 2.4800\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m Epoch 3/5\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2435 - loss: 2.5465\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2969 - loss: 2.6919\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.2135 - loss: 2.6738\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.3203 - loss: 2.3051\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.1641 - loss: 2.6776\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1162 - loss: 2.5347\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.1250 - loss: 2.8149\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.2188 - loss: 2.5751\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 4] loss:2.5474491119384766, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.2734 - loss: 2.3555\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.2500 - loss: 2.3684\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 0.1875 - loss: 2.7209\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2214 - loss: 2.5899\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.2370 - loss: 2.2292\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.2747 - loss: 2.6498\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2682 - loss: 2.3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m Epoch 5/5\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2344 - loss: 2.4858\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.1562 - loss: 3.0456\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1562 - loss: 3.1279\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3438 - loss: 2.1052\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/7\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1237 - loss: 2.5406 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0590 - loss: 2.7518    \n",
      "\u001b[36m(ClientAppActor pid=65410)\u001b[0m [Client 0] loss:2.7049448490142822, Client 0 accuracy:0.07000000029802322\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1162 - loss: 2.5556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65411)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3177 - loss: 2.2609\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.3438 - loss: 2.5241\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m Epoch 1/5\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.2760 - loss: 2.2631\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.3047 - loss: 2.3922\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.2188 - loss: 2.1943\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] loss:2.566208839416504, Client 4 accuracy:0.10999999940395355\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2812 - loss: 2.4070\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2891 - loss: 2.6908\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1680 - loss: 2.8922\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3919 - loss: 2.2194\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2344 - loss: 2.2951\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3268 - loss: 2.4819\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 4/5\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 97.59s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.321364402770996\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.340141177177429\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 2.334032416343689\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.397461771965027\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.476866364479065\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 2.496085524559021\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 2.545262098312378\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 2.5864557027816772\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 2.635576844215393\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 2.7039746046066284\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.10249999910593033),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.08250000327825546),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.10000000149011612),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.10000000149011612),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.10250000283122063),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.08999999985098839),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.08999999985098839),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.11250000074505806),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.08999999985098839),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.09750000014901161)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404ms/step - accuracy: 0.2734 - loss: 2.5314\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - accuracy: 0.2344 - loss: 2.5939\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1250 - loss: 2.9336\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 0] loss:2.732985496520996, Client 0 accuracy:0.07500000298023224\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1340 - loss: 2.5925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2747 - loss: 2.6424\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[1m4/7\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0495 - loss: 2.8346     \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0626 - loss: 2.7824\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=65412)\u001b[0m Epoch 5/5\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.1562 - loss: 2.5416\n",
      "\u001b[36m(ClientAppActor pid=65413)\u001b[0m [Client 2] loss:2.6749637126922607, Client 2 accuracy:0.11999999731779099\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Code to load the dataset\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLIENTS = 5\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def split_index(a, n):\n",
    "    s = np.array_split(np.arange(len(a)), n)\n",
    "    return s\n",
    "\n",
    "\n",
    "def generate_ann():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(32, 32, 3)),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Code to load the dataset\n",
    "def load_datasets(num_clients: int):\n",
    "    # Distribute it to train and test set\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalize data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    x_train, y_train = x_train[:10_000], y_train[:10_000]\n",
    "    x_test, y_test = x_test[:1000], y_test[:1000]\n",
    "\n",
    "    # Randomize the datasets\n",
    "    x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "    x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "    # Split training set into num_clients partitions to simulate the individual dataset\n",
    "    train_index = split_index(x_train, num_clients)\n",
    "    test_index = split_index(x_test, num_clients)\n",
    "\n",
    "    # Split each partition\n",
    "    train_ds = []\n",
    "    val_ds = []\n",
    "    test_ds = []\n",
    "    for cid in range(num_clients):\n",
    "        val_size = len(train_index[cid]) // 10\n",
    "        train_input_data, train_output_data = x_train[train_index[cid]], y_train[train_index[cid]]\n",
    "        val_input_data, val_output_data = train_input_data[:val_size], train_output_data[:val_size]\n",
    "        train_input_data, train_output_data = train_input_data[val_size:], train_output_data[val_size:]\n",
    "        train_dataset = (train_input_data, train_output_data)\n",
    "        val_dataset = (val_input_data, val_output_data)\n",
    "        test_dataset = (x_test[test_index[cid]], y_test[test_index[cid]])\n",
    "        train_ds.append(train_dataset)\n",
    "        val_ds.append(val_dataset)\n",
    "        test_ds.append(test_dataset)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n",
    "\n",
    "\n",
    "#TODO Client, client_fn, Server and simulation\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        self.net = train(self.net, self.trainloader, epochs=5)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"[Client {self.cid}] loss:{loss}, Client {self.cid} accuracy:{accuracy}\")\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "def client_fn(context: Context):\n",
    "    \"\"\"Returns a FlowerClient containing its data partition.\"\"\"\n",
    "    \n",
    "    # Create the model\n",
    "    net = generate_ann()\n",
    "    #get the identification\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    #Take the appropiate part of the dataset\n",
    "    trainloader = trainloaders[int(partition_id)]\n",
    "    valloader = valloaders[int(partition_id)]\n",
    "    #Create and return the Client\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "# Concstruct the ClientApp passing the client generation function\n",
    "client_app = ClientApp(client_fn=client_fn)\n",
    "\n",
    "\n",
    "\n",
    "from flwr.server import ServerApp, ServerAppComponents\n",
    "\n",
    "from typing import Tuple, List\n",
    "from flwr.common import Metrics\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    # instantiate the model\n",
    "    model = generate_ann()\n",
    "    params = get_parameters(model)# The federated model initial parameters\n",
    "    del model # this is not require but it saves a good amount of memory\n",
    "    # Convert model parameters to flwr.common.Parameters\n",
    "    global_model_init = fl.common.ndarrays_to_parameters(params)\n",
    "\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "            fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "            min_fit_clients=NUM_CLIENTS,  # Never sample less than NUM_CLIENTS clients for training\n",
    "            min_evaluate_clients=NUM_CLIENTS//2,  # Never sample less than NUM_CLIENTS//2 clients for evaluation\n",
    "            min_available_clients=NUM_CLIENTS,  # Wait until all NUM_CLIENTS clients are available\n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(params), # Initial parameters\n",
    "            evaluate_metrics_aggregation_fn=weighted_average,  # put the metric aggregation for the evaluation\n",
    "    )\n",
    "\n",
    "    # Define ServerConfig\n",
    "    config=fl.server.ServerConfig(num_rounds=10)\n",
    "\n",
    "    # Return the configuration and strategy for this server\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "    \n",
    "# Create Server\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b411f",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "To conclude this lesson, let's take a closer look at the key point of these strategies, which is the aggregation algorithm. These algorithms are responsible for combining the updates from the clients to generate the global model, and they are defined in the strategies as we have seen. Generally speaking, there are several types of aggregation that can be used in federated learning (Reddi et. al, 2020).  \n",
    "\n",
    "Here are the different types of aggregation that can be used in federated learning:\n",
    "\n",
    "* Federated averaging (`flwr.server.strategy.FedAvg`): In this approach, each device computes an update to the model parameters based on its local data, and these updates are then averaged together to create the global model. This approach is simple and effective, but it can be sensitive to the size of the updates and the quality of the data on each device.\n",
    "\n",
    "* Federated weighted averaging: This approach is similar to federated averaging, but each device's update is given a different weight based on the size of its data set or the quality of its data. This can help to give more influence to devices with larger or higher-quality data.\n",
    "\n",
    "* Federated averaging with momentum (`flwr.server.strategy.FedAvgM`): This approach is similar to federated averaging, but it incorporates a momentum term in order to smooth out the updates and help the model converge more quickly.\n",
    "\n",
    "* Federated stochastic gradient descent(`flwr.server.strategy.FedAdagrad`): In this approach, each device computes an update to the model parameters based on a small batch of its local data, rather than the entire data set. This can help to reduce the communication overhead and improve the convergence rate of the model.\n",
    "\n",
    "* Federated ADAM (`flwr.server.strategy.FedAdam`): This approach is a variant of federated stochastic gradient descent that uses the ADAM optimization algorithm to adaptively adjust the learning rate based on the gradient and second moment estimates.\n",
    "\n",
    "\n",
    "\n",
    "All of the previously mentioned aggregation methods, except for Federated Weighted Averaging, are implemented in the `flwr` framework and can be used with the different strategies. Additionally, there are other less common aggregation methods that can be employed. The choice of aggregation method will ultimately depend on the specific characteristics of the data and the requirements of the task at hand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1fc5f",
   "metadata": {},
   "source": [
    "#### References\n",
    "* Hard, A., Konečný, J., McMahan, H. B., Richemond-Barakat, C., Sivek, J. S., & Talwar, K. (2018). Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1812.02903.\n",
    "* Li, Y., Bonawitz, K., & Talwar, K. (2020). Fedprox: An optimizer for communication-efficient federated learning. arXiv preprint arXiv:2002.04283.\n",
    "* McMahan, H. B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2016). Communication-efficient learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629.\n",
    "* Yoon, J., Hard, A., Konečný, J., McMahan, H. B., & Sohl-Dickstein, J. (2018). Federal regression: A simple and scalable method for heterogeneous federated learning. arXiv preprint arXiv:1812.03862.\n",
    "* Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Konečný, J., Kumar, S. and McMahan, H.B., 2020. Adaptive federated optimization. arXiv preprint arXiv:2003.00295."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
